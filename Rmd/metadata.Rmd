---
title: ' Data Documentation & Metadata'
author: "ACCE Data Management Course"
date: "17 February 2017"
output:
  ioslides_presentation:
    css: css/ioslides_default.css
  html_document:
    css: css/sandstone.min.css
    fig_width: 5.5
    self_contained: no
    toc: yes
    toc_depth: 2
    toc_float: yes
---


<script>window.twttr = (function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0],
    t = window.twttr || {};
  if (d.getElementById(id)) return t;
  js = d.createElement(s);
  js.id = id;
  js.src = "https://platform.twitter.com/widgets.js";
  fjs.parentNode.insertBefore(js, fjs);

  t._e = [];
  t.ready = function(f) {
    t._e.push(f);
  };

  return t;
}(document, "script", "twitter-wjs"));</script>

```{r, echo = F}

if(names(rmarkdown::metadata$output)[1] == "html_document"){
    hash <- "#"}
if(names(rmarkdown::metadata$output)[1] == "ioslides_presentation"){
    hash <- ""}
```

<br>

## Documenting your data {.columns-2}

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/tomjwebb">@tomjwebb</a> I see tons of spreadsheets that i don&#39;t understand anything (or the stduent), making it really hard to share.</p>&mdash; Erika Berenguer (@Erika_Berenguer) <a href="https://twitter.com/Erika_Berenguer/status/556111838715580417">January 16, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/tomjwebb">@tomjwebb</a> Create a tab on your excel sheet that explains exactly what you did to get each part of the data and how you have treat it so far.</p>&mdash; Erika Berenguer (@Erika_Berenguer) <a href="https://twitter.com/Erika_Berenguer/status/556109844659597312">January 16, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<br>
<br>
<br>
<br>

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/tomjwebb">@tomjwebb</a> <a href="https://twitter.com/SuseJohnston">@SuseJohnston</a> Write comments into any data or code file as if for yourself one year from now when you won&#39;t recall the details.</p>&mdash; Albert Cardona (@albertcardona) <a href="https://twitter.com/albertcardona/status/556113639594528769">January 16, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<br>

## {.columns-2}

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/srsupp">@srsupp</a> <a href="https://twitter.com/tomjwebb">@tomjwebb</a> Document! Many sharing platforms exist (e.g. <a href="https://twitter.com/figshare">@figshare</a>), but w/o documentation/metadata, research data aren&#39;t v. useful</p>&mdash; Jonathan Petters (@jon_petters) <a href="https://twitter.com/jon_petters/status/556146541921320961">January 16, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/tomjwebb">@tomjwebb</a> <a href="https://twitter.com/ScientificData">@ScientificData</a> &quot;Document. Everything.&quot; Data without documentation has no value.</p>&mdash; Sven Kochmann (@indianalytics) <a href="https://twitter.com/indianalytics/status/556120920881115136">January 16, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<br>
<br>
<br>
<br>


<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="it" dir="ltr"><a href="https://twitter.com/tomjwebb">@tomjwebb</a> Annotate, annotate, annotate!</p>&mdash; CanJFishAquaticSci (@cjfas) <a href="https://twitter.com/cjfas/status/556109252788379649">January 16, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<br>

## {.columns-2}

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/tomjwebb">@tomjwebb</a> Have good metadata so others can understand it/use it</p>&mdash; Nathan B Furey (@NBFurey) <a href="https://twitter.com/NBFurey/status/556113773811867648">January 16, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/Sal_Keith">@Sal_Keith</a> +1 Metadata essential &amp; prerequisite for the new breed of data journals like <a href="https://twitter.com/ScientificData">@ScientificData</a> or repos like <a href="https://twitter.com/datadryad">@datadryad</a> <a href="https://twitter.com/tomjwebb">@tomjwebb</a></p>&mdash; Gavin Simpson (@ucfagls) <a href="https://twitter.com/ucfagls/status/556111062517284864">January 16, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<br>
<br>
<br>
<br>

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="und" dir="ltr">Document all the metadata (including protocols).<a href="https://twitter.com/tomjwebb">@tomjwebb</a></p>&mdash; Ward Appeltans (@WrdAppltns) <a href="https://twitter.com/WrdAppltns/status/556108414955560961">January 16, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

## 

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">You download a zip file of <a href="https://twitter.com/hashtag/OpenData?src=hash">#OpenData</a>. Apart from your data file(s), what else should it contain?</p>&mdash; Leigh Dodds (@ldodds) <a href="https://twitter.com/ldodds/status/828657155863638016">February 6, 2017</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<br>

## #otherpeoplesdata dream match!

> imagine an open data set

It's out there somewhere:

<br>

#### How would you locate it?

<br>

- what details would you need to know to determine relevance? 
- what information would you need to know to use it?
<br>

> #### Think about all you would neeed to understand someone else's data. In 18 months **YOU  will be that other person with your own data.**

<br>

## metadata 

> ### Information that **describes, explains, locates**, or in some way makes it easier to **find, access**, and **use** a resource (in this case, data). 

<br>

<img src="http://www.webhostingsecretrevealed.net/wp-content/uploads/2014/09/who-what-when-how-why.jpg" height="150px" width="300px">

<br>

<br>

#`r hash` exercise 2:

### introduce your data

<br>

## prepare it to share it 

### Let's start documenting your data!

- in pairs describe the **who, what, when, where, why** of your dataset.
- use the **Data Reuse Checklist** to guide your description.

### Data Reuse Checklist

http://mozillascience.github.io/checklist/

<br>
<br>

<img src="https://raw.githubusercontent.com/annakrystalli/ACCE_RDM/master/Rmd/assets/img/msl logo.png" height="100px" width="300px">

<br>

## metadata = data about data

#### Backbone of digital curation. Without it a digital resource may be irretrievable, unidentifiable or unusable. 


<p class="accent_border"><b>Descriptive</b></p>

- *enables identification, location and retrieval of data, often includes use of controlled vocabularies for classification and indexing.*

<p class="accent_border"><b>Technical</b></p>

- *describes the technical processes used to produce, or required to use a digital data object.*

<p class="accent_border"><b>Administrative</b></p>

- *used to manage administrative aspects of the digital object e.g. intellectual property rights and acquisition.*


This usually takes the form of a structured set of elements. 

<br>

## elements of metadata

- #### Structured data files:
    - readable by machines and humans, accessible through the web
- #### controlled vocabularies eg. [NERC Vocabulary server](https://www.bodc.ac.uk/resources/products/web_services/vocab/)
    - allows for connectivity of data
    
<img src="https://raw.githubusercontent.com/annakrystalli/ACCE_RDM/master/Rmd/assets/img/NERC_vocab.png" width=400px>   
    
### KEY TO SEARCH FUNCTION

By structuring & adhering to controlled vocabularies, data can be combined, accessed and searched!

<p class="accent_border"><b>Different communities develop different standards which define both the structure and content of metadata.</b></p>

<br>

## Ecological Metadata Language (EML) {.smaller}

#### last decade -> tremendous explosion of ecological and environmental data -> potential for broad-scale or synthetic research

<br>

### But  

- extremely heterogeneous and complexity 

- dispersed across many separate repositories. 

- ##### data are **largely unorganized and inaccessible**

<br>

### [**Ecological Metadata Language (EML)**](http://www.dcc.ac.uk/resources/metadata-standards/eml-ecological-metadata-language) 
#### a metadata standard developed by and for the ecology discipline. 

EML is a [set of XML schema](https://knb.ecoinformatics.org/#external//emlparser/docs/eml-2.1.1/index.html) documents that allow for the **structural expression of metadata**.


#### harmonising ecological data

<big>**Wide adoption and use of EML will create exciting new opportunities for data discovery, access, integration and synthesis.**</big>
 
<br>

## example EML

**EML = extensible markup language**: Emphasis on simplicity, generality, and usability across the Internet.

#### similar to html: what the web is made of!

```{r, echo=FALSE}
library(EML)
f <- system.file("xsd/test/eml.xml", package = "EML")
eml <- read_eml(f)
eml
```

<br>

## Documenting your data

- Start at the very least by **creating a metadata tab within your raw data spreadsheet**
- Ideally set up a system of **normalised tables** [see section 3 in this post](https://dynamicecology.wordpress.com/2016/08/22/ten-commandments-for-good-data-management/) and **`README`** and **`vignette`** documents to manage and document metadata.
- finally, when you're ready to publish:

### structure metadata into an `EML` file, a searchable, shareable file.

<br>      
	
#### **Different types data require different metadata**

<p class="accentborder"><b>Ensure everything someone might need to understand your data is documented</p></b>
    

<br>

## Example EML workflow

### Bird Trait Networks project 

<br> 
I'm using data from a project in which we ***compiled large dataset on bird reproductive, morphological, physiological, life history and ecological traits across as many bird species as possible*** to perform a network analysis on associations between trait pairs.

<br>

#### Let's use a simplified subset of the data to explore some of the concepts and tools from **producing an `eml`**

- all materials can be found [here](https://github.com/annakrystalli/ACCE_RDM/tree/master/example).

<br>

- I'll include some dummy data sourced from the `eml` package [vignette on creating an EML](https://github.com/ropensci/EML/blob/master/vignettes/creating-EML.Rmd) to cover broader scope of data.

```{r, message=FALSE, echo=F}
options(stringsAsFactors = FALSE)

knitr::opts_chunk$set(warning=FALSE, message=FALSE)

### SETTINGS ##############################################################
input.folder <- "assets/data/"

### FILES #################################################################

attr_tbl <- read.csv(paste(input.folder,"attr_tbl.csv", sep =""), stringsAsFactors = F)
dt   <- read.csv(paste(input.folder,"bird_trait_db-v0.1.csv", sep =""))
taxo <- read.csv(paste(input.folder,"taxo.csv", sep =""), stringsAsFactors = F)

### PACKAGES #################################################################

require(knitr)
require(listviewer)
library(tibble)

```

<br>

## data 

```{r, echo=FALSE}
kable(head(as_data_frame(dt), 9), caption = "bird trait networks dataTable")
```

- Like many real data sets, column headings are convenient for data entry and manipulation, but **not particularly descriptive to a user not already familiar with this data**. 

- More importantly, they **don't let us know what units they are measured in** (or in the case of categorical / factor data like species names or life stages, **what the factor abbreviations refer to**). So let us take a moment to be more explicit:



<br>

## EML rOpenScience package

<p class="accentborder"><b>We can store this information by creating EML files and explicity supply variable descriptions and units.</b></p>

![](http://ivanhanigan.github.io/images/workflow-rmd-md.png)

```{r, eval=FALSE}
install.packages("EML")
```


## EML

#### functions in the package help build an `eml` object from modular elements

    - eml
      - dataset
        - creator
        - title
        - publisher
        - pubDate
        - keywords
        - abstract 
        - intellectualRights
        - contact
        - methods
        - coverage
          - geographicCoverage
          - temporalCoverage
          - taxonomicCoverage
        - dataTable
          - entityName
          - entityDescription
          - physical
          - attributeList

<br>
          
## creating an EML

#### start with `dataTable`

        - dataTable
          - entityName
          - entityDescription
          - physical
          - attributeList

We will build this `eml` file from the bottom up, starting with the **two main components** of a `dataTable` indicated above: 

- `attributeList` 
- `physical`  
    
We will then slip these two pieces into place inside a dataTable element, and slip that into our eml element along with the rest of the generic metadata


<br>

## attributesList structure

### we need to supply two `data.frames`

- #### `attributes`
- #### `factors`

and a vector of:

- #### `columnClass`

<br>

- create a `attr_tbl` in which to complete all info required
- use **`eml_utils.R`** functions to extract `attributeList` elements from `attr_tbl`

```{r, eval=FALSE}
library(RCurl)
eval(parse(text = getURL(
    "https://raw.githubusercontent.com/annakrystalli/ACCE_RDM/master/R/eml_utils.R", 
    ssl.verifypeer = FALSE)))
```

```{r, echo = FALSE}
library(RCurl)
eval(parse(text = getURL(
    "https://raw.githubusercontent.com/annakrystalli/ACCE_RDM/master/R/eml_utils.R", 
    ssl.verifypeer = FALSE)), envir = environment())
```

<br>

## `attributes` df


The attributes data frame must use only the recognized column headers shown here. The attributes
data frame must contain columns for required metadata. These are:
For all data: 

- attributeName (required, free text field) 
- attributeDefinition (required, free text field)
- columnClasses (required, `"numeric"`, `"character"`, `"factor"`, `"ordered"`, 
    or `"Date"`, case sensitive)

<br>

#### `columnClasses` dependant attributes  

- For `numeric` (ratio or interval) data:
    - unit (required, see [eml-unitTypeDefinitions](https://knb.ecoinformatics.org/#external//emlparser/docs/eml-2.1.1/./eml-unitTypeDefinitions.html) and [working with units](https://github.com/ropensci/EML/blob/master/vignettes/working-with-units.Rmd))
- For `character` (textDomain) data: 
    - definition (required)
- For `dateTime` data: 
    - formatString (required)
    e.g for date `11-03-2001` formatString would be `"DD-MM-YYYY"`

<br>

## create `attr_tbl` shell

- #### load data
```{r, eval=FALSE}
dt   <- read.csv("data/bird_trait_db-v0.1.csv")
```


- #### create `attr_tbl` shell from **your data (`dt`)** 
    - use function `get_attr_shell` from `eml_utils.R`.

```{r}
attr_shell <- get_attr_shell(dt)
str(attr_shell)
```

## complete `attr_tbl`

#### save shell
- write `attr_shell` to `.csv`

```{r, eval=FALSE}
write.csv(attr_shell, file = "data/attr_shell.csv")
```
<br>

#### complete attr_tbl
- complete in excel and save to **attr_tbl.csv**
- read in completed **attr_tbl.csv**

```{r, eval=FALSE}
attr_tbl <- read.csv(file = "data/attr_tbl.csv")
```

<br>

## `attr_tbl`
```{r, echo = F}
if(names(rmarkdown::metadata$output)[1] == "html_document"){
kable(head(attr_tbl, 9), caption = "table 2. bird trait networks attr_tbl")}

if(names(rmarkdown::metadata$output)[1] == "ioslides_presentation"){
kable(head(attr_tbl[1:7], 9), caption = "table 2a. bird trait networks attr_tbl")}

```

##

```{r, echo = F}
if(names(rmarkdown::metadata$output)[1] == "ioslides_presentation"){
kable(head(attr_tbl[c(1,8:11)], 9), caption = "table 2b. bird trait networks attr_tbl")}

```

<br>

- I use the columns `code` and `levels` to store information on factors. Use `";"` to separate code and level descriptions. These can be extracted by `eml_utils.R` function `get_attr_factors()` later on.

## make `attributes` df
```{r}
attributes <- extract_attr_tbl(attr_tbl)
str(attributes, max.level = 2)
```

## make `factors` df

```{r}
factors <- get_attr_factors(attr_tbl)
kable(head(factors, 9))
```

## make attributeList

```{r}
library(EML)
attributeList <- set_attributes(attributes, factors, col_classes = attr_tbl$columnClasses)
str(attributeList, max.level = 2)
```

<br>

## set `physical`

#### document a description of the file format itself.

```{r}
physical <- set_physical("bird_trait_db-v0.1.csv")

physical

```

<br>

## assemble `dataTable`

we can now assemble the dataTable element itself by creating a new `dataTable` class

```{r}
dataTable <- new("dataTable",
                 entityName = "bird_trait_db-v0.1.csv",
                 entityDescription = "Subsample of bird trait database",
                 physical = physical,
                 attributeList = attributeList)
```

```{r}
str(dataTable, max.level = 2)
```

<br>

<br>

## set `coverage`

### set taxonomic coverage

Must either be a `data.frame` or `list` specifying **taxonomic information on species in data**.

<br>

#### Columns or list elements should contain rank names.

```{r eval=FALSE}
taxon_coverage <- read.csv("data/taxo.csv", stringsAsFactors = F)
```


```{r, echo=FALSE}
taxon_coverage <- taxo
head(as_data_frame(taxon_coverage))
```

##

### temporal and spatial coverage

my example doesn't have temporal or spatial coverage so I include some dummy information from the EML vignette.

```{r}
geographicDescription <- "The Geographic region of the kelp bed data extends 
along the California coast, down through the coast of Baja, Mexico: Central 
California (Halfmoon Bay to Purisima Point), Southern California (Point 
Arguello to the United States/Mexico border including the Channel Islands) 
and Baja California (points south of the United States/Mexico border including 
several offshore islands)"
```

#### set `coverage`

- supply taxonomic information to argument `sci_names`.

```{r}
coverage <- set_coverage(begin = '2012-06-01', end = '2013-12-31',
                         sci_names = taxon_coverage,
                         geographicDescription = geographicDescription,
                         west = -122.44, east = -117.15, 
                         north = 37.38, south = 30.00,
                         altitudeMin = 160, altitudeMaximum = 330,
                         altitudeUnits = "meter")
```

##

```{r}
eml_get(coverage, "geographicDescription")
eml_get(coverage, "temporalCoverage")
```


<br>

<br>

## create `methods`


#### document your protocols in a word .doc

Keep a dynamic document used to **plan**, **record** and **write up** methods. Again, for a more relevant example, I just include the example provided in the vignette. You can find a copy of the document [here](https://github.com/annakrystalli/ACCE_RDM/blob/master/example/methods/hf205-methods.docx)

```{r}
methods_file <- system.file("examples/hf205-methods.docx", package = "EML")
methods_file
methods <- set_methods(methods_file)

eml_get(methods, "methodStep")
```

<br>

<br>


## create person

it's important to be able to trace back the creator / maintainer of a dataset

```{r}
R_person <- as.person("Anna Krystalli <fakeaddress@email.com>")
anna <-as(R_person, "creator")

```


```{r}
HF_address <- new("address",
                  deliveryPoint = "Dept. Animal & Plant Science",
                  city = "Sheffield",
                  administrativeArea = "South Yorkshire",
                  postalCode = "S10 2TN",
                  country = "UK")
```

```{r}
contact <- 
  new("contact",
    individualName = anna@individualName,
    electronicMail = anna@electronicMailAddress,
    address = HF_address,
    organizationName = "University of Sheffield",
    phone = "000-000-0000")


```

##
```{r}
contact
```

## create a `keywordSet`

```{r}
keywordSet <-
  c(new("keywordSet",
        keywordThesaurus = "LTER controlled vocabulary",
        keyword = c("birds",
                    "animals",
                    "vertebrates")),
    new("keywordSet",
        keywordThesaurus = "trait categories",
        keyword =  c("life history", "ecology", "breeding biology", "mating system", "macroecology"))
  )
```


<br>

<br>

## final details

```{r}
pubDate <- "2017" 

title <- "Sub sample of bird macroecological trait variables"

abstract <- "The primary goal of this project is to compile a working example of an EML dataset using a subsample of the data from the bird trait networks project. The original dataset was compiled to examing the network structure between pair of a large number of traits. Additional files and objects were created to demonsted a broader example to ACCE research students"  

intellectualRights <- "This dataset is released to the public and may be freely
  downloaded. Please keep the designated Contact person informed of any
plans to use the dataset. Consultation or collaboration with the original
investigators is strongly encouraged. Publications and data products
that make use of the dataset must include proper acknowledgement"
```

 - or load abstract from a word file again by specifying the path to the .docx e.g.
```{r, eval=FALSE}
abstract <- as(set_TextType(abstract_file), "abstract")
```

<br>

<br>

## create `dataset`

```{r}
dataset <- new("dataset",
               title = title,
               creator = anna,
               pubDate = pubDate,
               intellectualRights = intellectualRights,
               abstract = abstract,
               keywordSet = keywordSet,
               coverage = coverage,
               contact = contact,
               methods = methods,
               dataTable = dataTable)
```

This step is modular. Remove any arguments you may have skipped.

<br>

<br>

## create `eml`

#### create `eml` class object

```{r}
library(uuid)
eml <- new("eml",
           packageId = uuid::UUIDgenerate(), 
           system = "uuid", # type of identifier
           dataset = dataset)
```

<br>

#### validate `eml`

```{r}
eml_validate(eml)

```

### success! 

<br>

## parsing your EML file

#### eg access `factors` from attributes:


```{r}
dtT <- eml_get(eml, "dataTable")
attrs <- eml_get(dtT, "attributeList")
attrs$factors

```

<br>

## save `eml`

```{r}
write_eml(eml, "example.xml")
```


#### The eml is now ready for combining with your data and [sharing](https://github.com/ropensci/EML/blob/master/vignettes/metadata-repositories.Rmd) through repositories.

<br>

<br>


#`r hash` exercise 3:

### create an `eml`

## create your own `eml`

<br>

#### get organised

<br>

- Add your data to the `data/` folder.
- create a new script eg `create_eml.R`
- load your data
- have a look at it with `Viewer(data)`
- create an `attr_shell` and complete it
- write a sample `methods .docx` document
- follow the steps to create your `eml`.

<br>

### The materials you create can form the basis for your RDM.

<br>

## sharing data {.columns-2}


### repositiories:

- #### [NERC data centres](http://www.nerc.ac.uk/research/sites/data/)

<img src="https://raw.githubusercontent.com/annakrystalli/ACCE_RDM/master/Rmd/assets/img/NERC.png" width="300px">

<br>
<br>
<br>
<br>
<br>


- #### [DRYAD](http://datadryad.org/)

<img src="https://raw.githubusercontent.com/annakrystalli/ACCE_RDM/master/Rmd/assets/img/dryad.png" width="300px">

<br>

- #### [figshare](https://figshare.com/)

<img src="https://raw.githubusercontent.com/annakrystalli/ACCE_RDM/master/Rmd/assets/img/figshare.png" width="300px">

<br>

## identify repositories

### these will dictate the appropriate controlled vocabulary and data structure.


#### [re3data.org](http://www.re3data.org/)

<img src="https://raw.githubusercontent.com/annakrystalli/ACCE_RDM/master/Rmd/assets/img/re3data.png" height="150px">

<br>

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/tomjwebb">@tomjwebb</a> Think early about where  you will archive your data. Ask repository for advice on format &amp; metadata standards <a href="https://twitter.com/Sal_Keith">@Sal_Keith</a> <a href="https://twitter.com/ucfagls">@ucfagls</a></p>&mdash; Scientific Data (@ScientificData) <a href="https://twitter.com/ScientificData/status/556120847078158337">January 16, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<br>

## using metadata in workflows


#### metadata can be extremely useful in analyses!

- accessing distributional/ statistical properties of variables.
- accessing the levels of factor data.
- accessing units and more informative descriptions for presentation.

<br>

eg. longer descriptions of variables, units and other useful metadata can be stored as part of dataframes in R using the function ```attributes()```

<br>

## Uses of metadata in analysis 

All r object have attributes and basic `data.frames` have 3. These can be accessed by using the same function.

```{r}
str(attributes(dt))

```

<br>

## Appending metadata as attributes 

So lets append some metadata to the **`dt`** data.frame as attributes. Indexing using the match function ensures the attributes are stores in order that match match the variable names

```{r}
descr.att <- attr_tbl$attributeDefinition[match(names(dt), attr_tbl$attributeName)]
names(descr.att) <- names(dt)
attributes(dt)$descr <- descr.att
  
units.att <- attr_tbl$unit[match(names(dt), attr_tbl$attributeName)]
names(units.att) <- names(dt)
attributes(dt)$units <- units.att
```

```{r}
str(attributes(dt))
```


<br>

## Accessing attributes 

So let's go ahead and make use of some of those attributes. There's a few ways they can be accessed. Say we want the `descr` attribute for all variables
```{r}
attr(dt, "descr")
```

<br>

## Accessing attributes 

So let's go ahead and make use of some of those attributes. There's a few ways they can be accessed. Say we want the `descr` attribute for all variables

```{r}
attributes(dt)$descr
```

<br>

## Working with attributes 

Let's make an axis label by combining the description and unit attributes using the `paste` function.

```{r}
descr <- attributes(dt)$descr["song.dur"]
unit <- attributes(dt)$unit["song.dur"]
label <- paste(descr, " (", unit, ")", sep = "")

plot(density(na.omit(dt[,"song.dur"])), main = label)
```


<br>

## next 

<br>

```{r, echo = F}

if(names(rmarkdown::metadata$output)[1] == "html_document"){
    url <- "https://annakrystalli.github.io/ACCE_RDM/docs/ROpenSci.html"}
if(names(rmarkdown::metadata$output)[1] == "ioslides_presentation"){
    url <- "file:///Users/Anna/Documents/workflows/ACCE_RDM/Rmd/ROpenSci.html"}
```


### [Open Science](`r url`)